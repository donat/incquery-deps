% ------------------------------------------------------------------------------
% 3 pages. Super figure which describes the entire solution. Choosing proper
% abstraction level for the %figure is essential. Every item on this figure will
% be an additional chapter in this paper.
% TODO:find a proper name for this chapter.
% ------------------------------------------------------------------------------
\chapter{Overview}

% My implementation.
As it was previously discussed, one of the most effective  way of achieving
smooth upgrades is to discover incoming dependencies. To achieve this, we
designed and implemented the \ptool{}. The the first part of the current chapter
gives an overview on the \ptool{} approach by describing the objectives of the
contained components. In the second part an example is introduced to make the
solution more understandable. 


\section{System Architecture}

\autoref{fig:superfigure.pdf}  shows the architecture of the \ptool{}.
\picr{superfigure.pdf}{Overview of the implemented system}
shows the overview of it. The system applies the standard server-client
architecture. The server side discovers the Java binaries, processes and stores
their structure and stores them in a database. The client side is an Eclipse
plugin, which gives the ability to the users to obtain and analyse the
dependency information about the softwares loaded into the workspace. The followings
detail the details of the individual components.


\subsection{System boundaries}
The system allows the users to examine the inter-project dependencies from the
development environment. It exposes two access points to access this
information. First the developer can initiate queries explicitly by selection
the target element from  he source code editor. The other option to check result
of the model queries (described later). This information is updated
automatically, every change in the development environment is reflected to the
result set. Both versions give visual representation of the result which the
developer can analyse and he can use it to make decisions what to and what not
to change in the source code.


\subsection{Repository management}
% Central repository management.
This component consists of the ''Source repository'' and the 'Binary component
repository'. They contain both the source code and the build binary version of
the internally developed softwares. These elements are centrally managed and
have a well-defined structure. The developers work on the source code and if
they finish one milestone they publish their improvements by putting the
compiled version into the binary repository through an automated process.
The binary repository is the input for the dependency analysis approach.

\subsection{The server side}
The server side is a standalone Java application which runs on a Linux server.
It has two functionality: 1) it discovers and stores the structure of the
products and 2) provides an interface for serving dependency queries. It has three
elements, the bytecode analyser, the dependency processor, and the storage engine.
The components of the server side are explained in detail in \autoref{sect:elabserver}.

\subsubsection{Bytecode analyser}
When a new binary jar file is discovered the bytecode analyzer  discovers the
internal structure and the dependency references. The result of the bytecode
analyser is an instance model representing the Java binary structure.

\subsubsection{Dependency processing}
The dependency processor takes the output of the bytecode analyzer, stores the 
structure of the Java binaries and tries to resolve the external references.
For both storing the structure and resolving the dependencies, this component
executes several queries on the dependency database. As a result, all structural
information are stored in this database, which serves the client queries too.


\subsection{The client side}
% Plugin
The client-side of the solution is an Eclipse plugin (or more precisely a set of
plugins) which gives the developer a convenient way to access to the dependency
information.

\subsubsection{Model load and direct queries}
The base of the plugin is the repository model loader. It provides a simple API
for accessing and querying the dependency information from the server. The
simple use-case for this, when the user directly asks the dependency information
from the Java source editor through UI contribution (marked as direct queries on
the figure).

\subsubsection{Workspace model creator}
The workspace model creator is module generating an EMF model describing the
state of the workspace. The generated model contains the loaded projects, the
contained packages, classes, methods, etc. The model also contains the
dependency structure between the elements (e.g. method calls, field accesses and
such). The information is gathered through the Eclipse Java Development Tools'
API. After the model is created it is incrementally maintained even through 
restarts.

\subsubsection{On-the-fly queries}
The pattern matcher module executes complex model queries on top of the acquired
models to provide dependency information. First it loads an EMF model from the
server describing the structure of all projects in the central repository.
Afterward the workspace model is loaded from the module described above. Both of
the models are loaded to the EMF-IncQuery engine. Through complex queries the two
models are joined and queried for the dependency information. With this more 
accurate and extensive dependency analysis can be achieved because this approach
takes into account the changes which were done in the workspace. The workspace 
model is updated upon every change of the workspace giving up-to-date feedback 
for the users while they are working on the development. 

\subsubsection{User Interface}
Both direct queries and the pattern matching module return the result in Eclipse 
views. After the result is evaluated, the user's responsibility to evaluate their
results and act accordingly.
\todo[inline]{UI szolgaltatasokat reszletesebben kifejteni, itemize}

\subsubsection{Implementation-specific requirements}
Using direct queries brings no limitations. The queries are simple remote method
calls and the result set is a relatively small data set which easy to store and
present on the Eclipse UI. On the other hand, the pattern matching solution is
far from being that easy, because in order to load make EMF-IncQuery work, the
entire repository has to be loaded. By default this model is a few hundred
megabytes sized in a serialized form. This implies that the implementation has to 
optimize this model without dropping useful information to make it loadable to 
the memory.

\section{Running Example: Service Provider Framework}\label{sect:spf}

To make the following chapters easier to understand, I am going to introduce a
simple use-case example. It is a design pattern called Service Provider
Framework. It is a practical application of the original Adapter pattern and it
was described in the famous book \emph{Effective Java} \cite{Bloch08}. This pattern
is the simplified version how the Java Database Connectivity (JDBC) works.

\subsection{Description}

\picr{exampleclasses.pdf}{Structure of Service Provider Framework design pattern}

You can see the structure of the pattern on
\autoref{fig:exampleclasses.pdf}. As of the packages it contains 3 major parts.
The \code{service} package contains the core pattern classes. The \code{impl}
and the \code{impl} packages are external users of the pattern and therefore
they are considered depending client libraries.

First let's discuss the pattern itself. The main goal for the patter is to
provide a registry of implementations for a desired service. This service is
described in the \code{Service} interface. The \code{Provider} interface is
serves as a factory instance; it has a single function to instantiate a new
Service object. The \code{Services} class has the role of the registry.
The service implementers register their implementation using the static
\code{registerProvider()} and \code{registerDefaultProvider()} methods. The
parameters the identifier string for the registered service and Provider
instance which will instantiate the Service instances. The clients will
instantiate the Service instance with the \code{newInstance()} function.
Depending the passed identifier string, the method will look up if a Provider
was registered with the same name, and if the answer is yes then it calls the
\code{Provider.newInstance()} and return its result.

The \code{DEFAULT\_PROVIDER\_NAME} is a static public field which can be used to
obtain the default Service implementation. The \code{AbstractService} is a
utility class which implements one of the function of the Service interface.

The \code{impl} package contains one possible implementation to use the
described pattern. The \code{BasicService} contains the implementation and the
\code{BasicProvider} is responsible for properly initializing and returning a
new instance of this version. The \code{BasicImplUtil} -- as its name implies --
holds utility classes which register the implementation in the Services class.

The \code{client} package holds one single \code{Main} class, which contains a
simple evaluation. It invokes the \code{Services.newInstance()} function passing
the default provider's name as an argument and invokes the \code{serviceA()} and
\code{serviceB()} function.

Although the example is fairly simple, the related source code can be found in
\autoref{examplesource}.

\subsection{Smooth upgrade challenges}
\todo[inline]{itemize-zal kiemelni a megoldando feldatokat, amelyeket majd megoldassz kesobb}
As it was described in the introduction we would like give the developers the
ability to check who is using the certain parts of the API. To present this this
pattern will be our use-case.

Imagine that the three packages are distributed into three different software
which have their individual developers. If somebody wants to change some parts
of the service without precisely knowing who is using which part of the code he
won't know how many dependant projects will be broken afterwards.

Let's see two examples. The responsible for the service package wants to modify
two parts of the classes: he wants to add a string parameter to the
\code{Service.serviceA()} method, and he wants to change the name of the
\code{Services.DEFAULT\_PROVIDER\_NAME} field. 

By using \ptool{} the developers are able to execute queries on any part of the
API. The result will be the primary starting point for considering what to do.
Three different outcome can happen: the selected part of the API doesn't have
dependencies, it has a few dependencies or it has got a lot and the developer's
decision depends on it. 

If there is no incoming dependency than any modifications can be done without
causing any compatibility issues. The developer can do whatever he wants.
If there is a lot of incoming dependency, than it means that the queried code
element is used by a lot of clients and any modifications would cause a build
error therefore backward compatibility has to be maintained. The third option is
that there are several dependencies. In this case the developer has to negotiate
with the clients how to proceed: he has to provide backward compatibility or the
clients has to align their code to the modifications.

\todo[inline]{eloreutalas a kesobbi fejezetekre, ahol a problemak megoldasa ki lesz fejtve}
