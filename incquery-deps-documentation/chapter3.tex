% ------------------------------------------------------------------------------
% 3 pages. Super figure which describes the entire solution. Choosing proper
% abstraction level for the %figure is essential. Every item on this figure will
% be an additional chapter in this paper.
% TODO:find a proper name for this chapter.
% ------------------------------------------------------------------------------

\chapter{Overview}
In this chapter\ldots

\section{Architecture}

% My implementation.
As it was discussed previously one of the most effective  way of achieving
smooth upgrades is to discover incoming dependencies. For this I designed and
implemented a solution called \ptool{}. \picr{superfigure.pdf}{Overview of the
implemented system} Figure \autoref{fig:superfigure.pdf} shows the overview of
it.

% CERN-related.
% NOTE, that the current implementation is bound to the CERN Control system's
% infrastructure. All used source and the way of getting them described by the
% internals. Let alone this fact, it is fairly simple to change the implementation
% to be usable in an arbitrary environment because only a tiny part of the code is
% responsibe to retrieve the required resources.

% Two implementation
This systems was implemented in two separate steps. My work at CERN covered an
implementation of a system which gives the ability to the users to query certain
parts of the source code for incoming dependencies. After my job was done I
created an extension which utilizes EMF-IncQuery to run faster, information-rich
and more extensive queries. Let's examine the elements of the figure one-by-one.

\subsection{Central repository management}
% Central repository management.
The first element on the figure is the ,,Central repository management''. It
refers all the internal resources CERN Control systems contains. Its central
element is a tool called \tool{Common Build} which is a build tool for Java
softwares. Common Build is an Apache Ant based software similar to Maven. It
provides functionality to describe and resolve dependencies, build, generate
documentation and release the softwares\footnote{Or \textit{products} as they
are referred at CERN}. The released softwares are put into a binary repository
which has a well-defined layout. On top of it, source repository is tightly
attached to the release repository; there is a 1-1 relationship between the
source code and the binaries.

\subsection{The server side}
The server side is a standalone Java application which runs on a Linux server.
It has two functionality: 1) it discovers and stores the structure of the
products and 2) provides an interface for serving dependency queries. 

For discovering, the process listens if a new release happens in the repository.
If it happens the freshly added binaries (jar files) are passed to the byte code
analysis module which parses the file and discovers the contained structure and
the dependencies utilizing the Apache BCEL library.  The structure and the
dependencies are passed to the storage engine to store it. The storage engine
itself defines a set of operations to find, store and retrieve certain subset of
the model. The remote query interface also use this module to get the necessary 
dependency information for the clients.

\subsection{The client side}
% Plugin
The client-side of the solution is an Eclipse plugin (or more precisely a set of
plugins) which gives the developer a convenient way to access to the dependency
information.

% Model load and direct queries
The base of the plugin is the repository model loader. It provides a simple API
for accessing and querying the dependency information from the server. The
simple use-case for this, when the user directly asks the dependency information
from the Java source editor through UI contribution (marked as direct queries on
the figure).

% ws model creator
The workspace model creator is module generating an EMF model describing the
state of the workspace. The generated model contains the loaded projects, the
contained packages, classes, methods, etc. The model also contains the
dependency structure between the elements (e.g. method calls, field accesses and
such). The information is gathered through the Eclipse Java Development Tools'
API. After the model is created it is incrementally maintained even through 
restarts.

% pattern maching over.
The pattern matcher module executes complex model queries on top of the acquired
models to provide dependency information. First it loads an EMF model from the
server describing the structure of all projects in the central repository.
Afterward the workspace model is loaded from the module described above. Both of
the models are loaded to the EMF-IncQuery engine. Through complex queries the two
models are joined and queried for the dependency information. With this more 
accurate and extensive dependency analysis can be achieved because this approach
takes into account the changes which were done in the workspace. The workspace 
model is updated upon every change of the workspace giving up-to-date feedback 
for the users while they are working on the development. 

% Interface.
Both direct queries and the pattern matching module return the result in Eclipse 
views. After the result is evaluated, the user's responsibility to evaluate their
results and act accordingly.

% limitation.
Using direct queries brings no limitations. The queries are simple remote method
calls and the result set is a relatively small data set which easy to store and
present on the Eclipse UI. On the other hand, the pattern matching solution is
far from being that easy, because in order to load make EMF-IncQuery work, the
entire repository has to be loaded. By default this model is a few hundred
megabytes sized in a serialized form. This implies that the implementation has to 
optimize this model without dropping useful information to make it loadable to 
the memory.

\section{Service Provider Framework}

\subsection{Description of the pattern}

To make the following chapters easier to understand, I am going to introduce a
simple use-case example. It is a design pattern called Service Provider
Framework. It is a practical application of the original Adapter pattern and it
was described in the famous book ,,Effective Java'' \cite{Bloch08}. This pattern
is the simplified version how the Java Database Connectivity (JDBC) works.

\picr{exampleclasses.pdf}{Structure of Service Provider Framework pattern}

You can see the structure of the pattern on figure
\autoref{fig:exampleclasses.pdf}. As of the packages it contains 3 major parts.
The \code{service} package contains the core pattern classes. The \code{impl}
and the \code{impl} packages are external users of the pattern and therefore
they are considered depending client libraries.

First let's discuss the pattern itself. The main goal for the patter is to
provide a registry of implementations for a desired service. This service is
described in the \code{Service} interface. The \code{Provider} interface is
serves as a factory instance; it has a single function to instantiate a new
Service object. The \code{Services} class has the role of the registry.
The service implementers register their implementation using the static
\code{registerProvider()} and \code{registerDefaultProvider()} methods. The
parameters the identifier string for the registered service and Provider
instance which will instantiate the Service instances. The clients will
instantiate the Service instance with the \code{newInstance()} function.
Depending the passed identifier string, the method will look up if a Provider
was registered with the same name, and if the answer is yes then it calls the
\code{Provider.newInstance()} and return its result.

The \code{DEFAULT\_PROVIDER\_NAME} is a static public field which can be used to
obtain the default Service implementation. The \code{AbstractService} is a
utility class which implements one of the function of the Service interface.

The \code{impl} package contains one possible implementation to use the
described pattern. The \code{BasicService} contains the implementation and the
\code{BasicProvider} is responsible for properly initializing and returning a
new instance of this version. The \code{BasicImplUtil} -- as its name implies --
holds utility classes which register the implementation in the Services class.

The \code{client} package holds one single \code{Main} class, which contains a
simple evaluation. It invokes the \code{Services.newInstance()} function passing
the default provider's name as an argument and invokes the \code{serviceA()} and
\code{serviceB()} function.

Although the example is fairly simple, the related source code can be found in
appendix \autoref{examplesource}.

\subsection{Description of the problem}
So why are we looking at this example? Imagine that the three packages are
distributed into three different software which have their individual
developers. If somebody wants to change some parts of the service without
precisely knowing who is using which part of the code he won't know how many
dependant projects will be broken afterwards.

Let's see two examples. The responsible for the service package wants to modify
two parts of the classes: he wants to add a string parameter to the
\code{Service.serviceA()} method, and he wants to change the name of the
\code{Services.DEFAULT\_PROVIDER\_NAME} field. I will show how the solutions
presented in this paper let the developer figure out, who is using these parts
of the code and how can he resolve this problem.

