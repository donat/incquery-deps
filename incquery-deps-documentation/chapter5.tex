\chapter{Evaluation}
%------------------------------------------------------------------------------
%3-4 pages. Functional evaluation. Performance evaluation. 
%------------------------------------------------------------------------------

\section{Example revisited}

After showing the details of the implementation, let's see it in action.
We will use the tool to solve the problem described in \autoref{sect:spf}. We
will go though on every component and check what is happening there with the
example. 

Let's start with the repositories. In our example the source and the binary
repository contains three projects, each of them holds one package from the
example. the name of the projects are service, client and impl, the name of 
the jars files respectively service.jar, client.jar and impl.jar. For the sake
of simplicity we have only one version from each project. 

\subsection{On the server side}


Now let's move forward to the server process and the dependency analysis. As 
the binary projects appear in the repository, they get discovered by the 
server process. 

The first step in the process is the bytecode analysis. In this phase the
structure and the reference of the dependencies are discovered from the
binaries. As of the structure the analyzer finds 3 projects, 8 classes 2 fields
and 19 methods which get stored in the database.
The methods are composed of the 12 defined methods, 6 constructor (from all
non-interface classes) and 1 static initializer (which comes from the Services
class as it gives a default value to a static field).

The discovered dependencies are formatted and filtered in order not to have
internal or platform defined elements (dependencies pointing inside the
\code{java.*} package). For example let's see the \code{BasicImplUtil} class'
\code{registerImplementation()} method.
\begin{tabl}
{External references of the BasicImplUtil.registerImplementation() method}
{extrefs}{|p{.37\linewidth}|p{.37\linewidth}|p{.2\linewidth}|}
\hline
	\textbf{Binary format}						&  
	\textbf{Source format} 						& 
	\textbf{Type} 								\\
\hline
	impl/BasicProvider  						&
	impl.BasicProvider 							&
	ConstClass 									\\
\hline
	service/Services/registerProvider 
	\mbox{(Ljava/lang/String;}
	\mbox{Lservice/Provider;)V} 				& 
	\mbox{service.Services.registerProvider}
	\mbox{(java.lang.String,}
	\mbox{service.Provider):void} 				&
	\mbox{Constant} \mbox{MethodRef} 			\\
\hline
\end{tabl}
The first one is a 
\code{ConstantMethodRef} type reference. During the analysis they are first converted
The first one is a class reference the second one is a method reference.
The references are formatted to source format as it is shown in the second column.
Now the first references is eliminated from the list, because it points inside the 
\code{impl} project. However the second one does not, so it remains at its place.  

The dependency processor takes the remaining dependencies from the elements and 
searches the database if there is one. In case of our method reference, the processor
finds that there is a \code{registerProvider()} method defined with the same exact 
signature signature in the database. Because the reference was stored on the called 
method list, the processor creates a new method call dependency starting from 
\code{impl.BasicImplUtil} targeting \code{Services.registerProvider()}.

At this point the storage engine stores all the structure and the dependencies 
of the three products. The schema of the Oracle database implementation and the EMF
database was described in details previously. Now let's check how this data can be used 
on the client side.

\subsection{On the client side}

To continue our example, we will examine the view of the developer who knows
only about his own \code{service} project. If the \ptool{} is  installed in his
Eclipse, the EMF model -- shown on \autoref{fig:wsmodel.png}
\picr{wsmodel.png}{Workspace model containing Service package from the example}
-- is built and synchronized automatically. On the figure we can see, that the
structure of the project (left) corresponds to the content of the EMF model
(right). In the model view, you can also see that the in-project dependency
relationships are also registered.


Because the \code{client} and the \code{impl} projects have references to the
\code{service} project, both of them are loaded to the repository model. It has all the
element but with the compacted version, so no fully qualified names. But because
there is no overlapping names between the classes and method than the compacted
model does not introduce false-positive results.

Let's see how the developer checks the incoming dependencies through the
explicit queries.
\pic{incdeps.png}{Execute explicit queries from the source code editor}
\autoref{fig:incdeps.png} shows the context menu contribution for initiating an
explicit query. The query takes a few seconds to respond. The results are shown
in the viewer like on \autoref{fig:results.png}.
\picr{results.png}{Result of explicit queries}
 
The same result can be retrieved using model queries, but without any
interaction: all result for the selected project is automatically showed. Plus,
if something is changed, for example the \code{serviceB()} method is deleted, it
i) is compared against the repository model and marked as deleted method and all
the incoming dependencies is listed as a possible impact if the modified code
gets committed. 
\todo[inline]{put image of the result of the model queries}

Back to example. The developer checks the incoming dependencies of the
\mbox{\code{Services.}} \mbox{\code{DEFAULT\_PROVIDER\_NAME}} field and the \code{Service.serviceA()}
method. In the first case there are some incoming dependencies which can be
examined.
In our example there are two external users of the field, so the developer can
either contact them and coordinate the smooth upgrades by simultaneously
releasing a new versions of all projects. On the other side, the
\code{serviceA()} method has no incoming dependencies, as nobody uses it. In
this case the developer has the right to change the signature however he wants.


\section{Performance}
After the functionality was presented, let's check the overall performance of
the system. We have to check the individual components  that they can complete
their requirement as the input or usage scales up to a level of the production
applications. First we have to verify whether the dependency fast enough and can
process large number of Java binaries. The next one is to see if the explicit
queries are reasonably fast. The last yet the most important is to test to
performance of the EMF-IncQuery engine how big instance models can be loaded
into the EMF-IncQuery engine.

The jar files used as the sample data come from real-life applications; they are
operational softwares from the CERN controls systems. By using them we can
eliminate the problems of having badly generated homogeneous sample data.

\subsection{Dependency processing}
The first element to measure is how the server process perform.
A measurement has to check how efficiency the bytecode analysis and the
dependency processing together works. Minimal preliminary requirement is that is
should be much faster then the source code of the software in  the repository
changes, because otherwise the dependency database will contain constantly
outdated information.

As a test I took all of the import binaries, started the server process as a
standalone Java application, initiated the dependency discovery on the subset of
the binaries and measured the statistics of the database and the speed of the
discovery. After the test has finished I erased the database and repeated the
test with a bigger and bigger subset of the jar files until the entire set was
analyzed. For the test I used a desktop computer with the following
specifications:
\begin{itemize}
  \item Processor: Intel Core i3-2120, 3,3 GHz,
  \item RAM: 8GB DDR3,
  \item OS: Windows 7 Enterprise, 64 bit, Service Pack 1,
  \item JVM: Oracle JDK 1.6.0\_27-b07.
\end{itemize}
The tests showed that on average one project contains 80 classes, 513 methods, 304 fields and 778 dependencies. 
The result of the test are shown on \autoref{fig:resanal.pdf}
\picr{resanal.pdf}{Result of dependency processing measurement}
The left chart shows how big generated EMF instance model depending on the
input jar size. It is clearly visible that the size linearly increases
as the input grows. Also the execution time (right chart) shows 
steady growth as the input size increases. Looking at the analysis
 of all (1300) jars, the average processing takes roughly $0,43$ seconds.
Knowing that even in large software repositories usually a few, maybe a few 
dozen releases happen, then having a system which analyses the differences within
a second is more than enough.

\subsection{Explicit queries}
Next question is how fast are the explicit queries. We want to see that the
results of a dependency query returns the data and visualizes the information
within reasonable time even when the result set bigger than usual. 

I set up the server process on the same machine, what I used for 
testing the dependency processing. I filled the database with with all the
dependency information. For measuring the speed of the queries used an average
virtual machine which from the CERN ecosystem which has similar specification
what is usually used for development:
\begin{itemize}
  \item Processor: Intel Xenon E5645, 2,4 GHz,
  \item RAM: 4GB DDR3,
  \item OS: Windows 7 Enterprise, 32 bit, Service Pack 1,
  \item JVM: Oracle JDK 1.6.0\_35-b10.
\end{itemize}
Because this machine runs on a virtualized infrastructure it can't be
considered as a steady platform; performance could change as the usage changes,
but it is strong enough for comfortable Java development. 

For the tests I chose a specific project which happens to be a widely-used
library by the other jars. During the measurement a query is initiated for 
the incoming dependencies for every single element of this project. 
I dropped the result where there was no dependencies and made a statistics, how 
the size of the result set affects on the response time.
The results are shown on \autoref{fig:expqmeasure.pdf}.
 \picfifty{expqmeasure.pdf}{Explicit queries measurement result}
As it turned out, that the response time does not depend on the size of the result,
it was returned roughly 200ms on every sample. This result means that utilizing 
dependency queries return the result in reasonable time. 


 
Model queries:
 * Eclipse involved: hard to query the performance of individual plugins.
 * Simple use-case: how big model can fit into the memory without having
 performance penalties.
 * Practical, the overall memory consumption counts anyway.
 * input:repository model transformed into the compacted model.
 * measure:
   * original size. compacted size. load model size. initialization time. heap
   size. reaction time.
 * Verdict: Loading huge model but if  software repository does not contain
 super projects, reasonable to load a subset which is small enough to  hold it
 in the db. In return extra fast. 
